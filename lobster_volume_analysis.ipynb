{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjxzDwXNZ0WH"
      },
      "outputs": [],
      "source": [
        "!pip install fastdtw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Here we have useful import\n",
        "import os, os.path, requests, zipfile, io\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "from pathlib import Path\n",
        "\n",
        "import plotly\n",
        "import plotly.io as pio\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "from matplotlib.patches import ConnectionPatch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy.spatial.distance as dist\n",
        "\n",
        "# Configuring Matplotlib\n",
        "import matplotlib as mpl\n",
        "mpl.rcParams['figure.dpi'] = 300\n",
        "savefig_options = dict(format=\"png\", dpi=300, bbox_inches=\"tight\")\n",
        "\n",
        "# Computation packages\n",
        "from scipy.spatial.distance import euclidean\n",
        "from fastdtw import fastdtw\n",
        "\n",
        "# Plotting package\n",
        "import seaborn as sbn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCQLK65oaNvi"
      },
      "source": [
        "## Set constant variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FAc7oRjWaLuo"
      },
      "outputs": [],
      "source": [
        "# Google Colab\n",
        "# LOCAL_PATH = \"/content/dataset\"\n",
        "# Local\n",
        "LOCAL_PATH = \"dataset\"\n",
        "\n",
        "DIR_DATA = \"dataset/\"\n",
        "\n",
        "# Name: \tTICKER_Year-Month-Day_StartTime_EndTime_message_LEVEL.csv \t\n",
        "\n",
        "TICKERS = [\"AMZN\", \"AAPL\", \"GOOG\", \"INTC\", \"MSFT\"]\n",
        "\n",
        "START_TIME = \"34200000\" \n",
        "END_TIME = \"57600000\" \n",
        "\n",
        "MESSAGE = [\"message\", \"orderbook\"]\n",
        "\n",
        "YEAR = \"2012\"\n",
        "MONTH = \"06\"\n",
        "DAY = \"21\"\n",
        "DATE = YEAR + \"-\" + MONTH + \"-\" + DAY\n",
        "START_DATE_DT = dt.datetime.strptime(DATE, \"%Y-%m-%d\")\n",
        "\n",
        "LEVEL = \"1\"\n",
        "\n",
        "MESSAGE_COLUMNS = [\"time\", \"event_type\", \"order_id\", \"size\", \"price\", \"direction\"]\n",
        "EXECUTED_ORDER_MESSAGES = [4,5] # 4 and 5 refers to the executed trades\n",
        "\n",
        "# 1 SEC, 10 SEC, 1MIN, 1 HOUR\n",
        "UNIT_TIME = \"60s\"\n",
        "\n",
        "# Set true if you want to normalize the data\n",
        "NORMALIZE = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdCedOLyaQdk"
      },
      "source": [
        "## Check Directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsMd5pGPaSmK",
        "outputId": "a9043854-0b20-4c75-c70c-2bdc086facc3"
      },
      "outputs": [],
      "source": [
        "# First we create the directory where to save the CSV files\n",
        "if os.path.exists(LOCAL_PATH):\n",
        "  print(\"Directory dataset exists!\")\n",
        "else:\n",
        "  directory = \"dataset\"\n",
        "  os.mkdir(directory) \n",
        "  print(\"Directory '% s' created\" % directory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EEc1i-cavlH"
      },
      "source": [
        "## Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Hcsrh6alGLE"
      },
      "source": [
        "#### Functions to manage the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xawZpedVc3oM"
      },
      "outputs": [],
      "source": [
        "def get_dataframe(ticker, msg_ord, msg_ord_col):\n",
        "  \"\"\"\n",
        "  Read Dataset From a csv file\n",
        "  Args:\n",
        "    tricker: string, name of the action (\"AMZN\", \"AAPL\", \"GOOG\", \"INTC\", \"MSFT\").\n",
        "    msg_ord: string, it atcs like a flag, the two possible values are \"message\" and \"orderbook\".\n",
        "    msg_ord_col: list of string, all values for the \"message\" or \"orderbook\" columns.\n",
        "  Return:\n",
        "   df: pandas dataframe.\n",
        "  \"\"\"\n",
        "  FORMAT_FILE = \"{}_{}\" + \"_\" + START_TIME + \"_\" + END_TIME + \"_\" + msg_ord + \"_\" +\"{}.csv\"\n",
        "  df = pd.read_csv(DIR_DATA + FORMAT_FILE.format(ticker, DATE, LEVEL), names=msg_ord_col)\n",
        "  return df\n",
        "\n",
        "\n",
        "def compute_orderbook_columns(level: int):\n",
        "  \"\"\"\n",
        "  Function to compute the orderbook columns name\n",
        "  Args: \n",
        "     level: int.\n",
        "  Return: \n",
        "    orderbook_columns: list of string\n",
        "  \"\"\"\n",
        "  orderbook_columns = []\n",
        "  for i in range(1, level+1):\n",
        "    orderbook_columns += [\"sell\"+str(i), \"vsell\"+str(i), \"buy\"+str(i), \"vbuy\"+str(i)]\n",
        "  return orderbook_columns\n",
        "\n",
        "\n",
        "def compute_joined_lob(message_df, orderbook_df):\n",
        "  \"\"\"\n",
        "  Function to join the Message and Orderbook datsets\n",
        "  Args:\n",
        "    message_df: pandas dataframe\n",
        "    orderbook_df: pandas dataframe\n",
        "  Return:\n",
        "    joined_lob_df: pandas dataframe\n",
        "  \"\"\"\n",
        "  joined_lob_df = message_df.copy()\n",
        "  # Create new columns and initialize their values\n",
        "  joined_lob_df[ORDERBOOK_COLUMNS] = orderbook_df\n",
        "  # Add date column to the dataframe\n",
        "  joined_lob_df.insert(0, \"date\", [START_DATE_DT + dt.timedelta(seconds=i) for i in joined_lob_df[\"time\"]])\n",
        "  return joined_lob_df\n",
        "\n",
        "\n",
        "\n",
        "def compute_ohlc_volume(df):\n",
        "  \"\"\"\n",
        "  Function to compute the OHCL dataset template\n",
        "  Args:\n",
        "    df: pandas dataframe\n",
        "  Return:\n",
        "    df: pandas dataframe\n",
        "  \"\"\"\n",
        "  executed_trades_messages = df[(df[\"event_type\"].isin(EXECUTED_ORDER_MESSAGES))]\n",
        "  # We want the price in dollar so we divided by 10000\n",
        "  executed_trades_messages[\"price\"] = executed_trades_messages[\"price\"] / 10000\n",
        "  executed_trades_messages.index = executed_trades_messages[\"date\"]\n",
        "  # Compute the OHLC\n",
        "  df = executed_trades_messages[\"price\"].resample(UNIT_TIME).ohlc()\n",
        "  # Compute the volume\n",
        "  df[\"volume\"] = executed_trades_messages[\"size\"].resample(UNIT_TIME).sum()\n",
        "  # Manage the missing values (NaN) and in the volume where we have missing values we want 0!\n",
        "  df[[\"open\", \"high\", \"low\", \"close\"]] = df[[\"open\", \"high\", \"low\", \"close\"]].fillna(method=\"ffill\")\n",
        "  df[[\"open\", \"high\", \"low\", \"close\"]] = df[[\"open\", \"high\", \"low\", \"close\"]].fillna(method=\"bfill\")\n",
        "  df[\"volume\"] = df[\"volume\"].fillna(0)\n",
        "  return df\n",
        "\n",
        "\n",
        "\n",
        "def compute_r(df, k=5):\n",
        "  \"\"\"\n",
        "  Function to compute the R values, using Rolling Mean\n",
        "  Args:\n",
        "    df: pandas dataframe\n",
        "  Return:\n",
        "    df: pandas dataframe\n",
        "  \"\"\"\n",
        "  # mean k previous values\n",
        "  m_minus = df[\"open\"].rolling(k).mean() \n",
        "  # mean k future values\n",
        "  m_plus = df[\"open\"].shift(-(k-1)).rolling(k).mean() \n",
        "  df[\"R\"] = (m_plus - m_minus) / m_minus\n",
        "  df[\"R\"] = df[\"R\"].fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oe1ae1AQaYAT"
      },
      "outputs": [],
      "source": [
        "def select_date_range(df, start_date, end_date): \n",
        "  #greater than the start date and smaller than the end date\n",
        "  mask = (df['date'] > start_date) & (df['date'] <= end_date)\n",
        "  df = df.loc[mask]\n",
        "  return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Z-EzGxGkrlw"
      },
      "source": [
        "### Bollinger Bands"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Q44NrX4kzvc"
      },
      "source": [
        "#### Compute Bollinger Bands"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__5CffX0ku41"
      },
      "outputs": [],
      "source": [
        "def compute_bollinger_band(data, col_name):\n",
        "  \"\"\"\n",
        "  Function to compute the bollinger bands using a window of 20 days\n",
        "  Args:\n",
        "    data: pandas dataframe\n",
        "    col_name: string, \"close\" or \"volume\"\n",
        "  Return:\n",
        "    buyers, sellers, upper_band, lower_band, sma: list\n",
        "  \"\"\"\n",
        "  df = data[[col_name]]\n",
        "  sma = df.rolling(window=20).mean().dropna()\n",
        "  rstd = df.rolling(window=20).std().dropna()\n",
        "\n",
        "  upper_band = sma + 2 * rstd\n",
        "  lower_band = sma - 2 * rstd\n",
        "\n",
        "  upper_band = upper_band.rename(columns={col_name: 'upper'})\n",
        "  lower_band = lower_band.rename(columns={col_name: 'lower'})\n",
        "  bb = df.join(upper_band).join(lower_band)\n",
        "  bb = bb.dropna()\n",
        "\n",
        "  buyers = bb[bb[col_name] <= bb['lower']]\n",
        "  sellers = bb[bb[col_name] >= bb['upper']]\n",
        "\n",
        "  return buyers, sellers, upper_band, lower_band, sma"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kx417KLpapD2"
      },
      "source": [
        "#### Plot Bollinger Bands"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LM8mNlVAardG"
      },
      "outputs": [],
      "source": [
        "def plot_bollinger_band(buyers, sellers, upper_band, lower_band, sma, data, col_name, ticker):\n",
        "  # pio.templates.default = \"plotly_dark\"\n",
        "\n",
        "  fig = go.Figure()\n",
        "  fig = make_subplots(rows=1,cols=1)\n",
        "  fig.add_trace(go.Scatter(x=lower_band.index, \n",
        "                          y=lower_band['lower'], \n",
        "                          name='Lower Band', \n",
        "                          line_color='rgba(173,204,255,0.2)'\n",
        "                          ))\n",
        "  \n",
        "  fig.add_trace(go.Scatter(x=upper_band.index, \n",
        "                          y=upper_band['upper'], \n",
        "                          name='Upper Band', \n",
        "                          fill='tonexty', \n",
        "                          fillcolor='rgba(173,204,255,0.2)', \n",
        "                          line_color='rgba(173,204,255,0.2)'\n",
        "                          ))\n",
        "  \n",
        "  fig.add_trace(go.Scatter(x=data.index, \n",
        "                          y=data[col_name], \n",
        "                          name=col_name, \n",
        "                          line_color='#636EFA'\n",
        "                          ))\n",
        "  \n",
        "  fig.add_trace(go.Scatter(x=sma.index, \n",
        "                          y=sma[col_name], \n",
        "                          name='SMA', \n",
        "                          line_color='#FECB52'\n",
        "                          ))\n",
        "  if col_name == \"close\":\n",
        "    fig.add_trace(go.Scatter(x=buyers.index, \n",
        "                            y=buyers[col_name], \n",
        "                            name='Buyers', \n",
        "                            mode='markers',\n",
        "                            marker=dict(\n",
        "                                color='#00CC96',\n",
        "                                size=10,\n",
        "                                )\n",
        "                            ))\n",
        "    \n",
        "    fig.add_trace(go.Scatter(x=sellers.index, \n",
        "                            y=sellers[col_name], \n",
        "                            name='Sellers', \n",
        "                            mode='markers', \n",
        "                            marker=dict(\n",
        "                                color='#EF553B',\n",
        "                                size=10,\n",
        "                                )\n",
        "                            ))\n",
        "  if col_name == \"volume\":\n",
        "    fig.add_trace(go.Scatter(x=sellers.index, \n",
        "                        y=sellers[col_name], \n",
        "                        name='High Volume', \n",
        "                        mode='markers',\n",
        "                        marker=dict(\n",
        "                            color='#00CC96',\n",
        "                            size=10,\n",
        "                            )\n",
        "                        ))\n",
        "\n",
        "  \n",
        "  # Set title\n",
        "  fig.update_layout(title_text=ticker+\" \"+col_name)\n",
        "\n",
        "  fig.update_yaxes(autorange = True, fixedrange= False)\n",
        "\n",
        "\n",
        "  fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCNtquRvabpv"
      },
      "source": [
        "### DTW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xuvbiDtacox"
      },
      "outputs": [],
      "source": [
        "def dp(dist_mat):\n",
        "    \"\"\"\n",
        "    Find minimum-cost path through matrix `dist_mat` using dynamic programming.\n",
        "\n",
        "    The cost of a path is defined as the sum of the matrix entries on that\n",
        "    path. See the following for details of the algorithm:\n",
        "\n",
        "    - http://en.wikipedia.org/wiki/Dynamic_time_warping\n",
        "    - https://www.ee.columbia.edu/~dpwe/resources/matlab/dtw/dp.m\n",
        "\n",
        "    The notation in the first reference was followed, while Dan Ellis's code\n",
        "    (second reference) was used to check for correctness. Returns a list of\n",
        "    path indices and the cost matrix.\n",
        "    \"\"\"\n",
        "\n",
        "    N, M = dist_mat.shape\n",
        "    \n",
        "    # Initialize the cost matrix\n",
        "    cost_mat = np.zeros((N + 1, M + 1))\n",
        "    for i in range(1, N + 1):\n",
        "        cost_mat[i, 0] = np.inf\n",
        "    for i in range(1, M + 1):\n",
        "        cost_mat[0, i] = np.inf\n",
        "\n",
        "    # Fill the cost matrix while keeping traceback information\n",
        "    traceback_mat = np.zeros((N, M))\n",
        "    for i in range(N):\n",
        "        for j in range(M):\n",
        "            penalty = [\n",
        "                cost_mat[i, j],      # match (0)\n",
        "                cost_mat[i, j + 1],  # insertion (1)\n",
        "                cost_mat[i + 1, j]]  # deletion (2)\n",
        "            i_penalty = np.argmin(penalty)\n",
        "            cost_mat[i + 1, j + 1] = dist_mat[i, j] + penalty[i_penalty]\n",
        "            traceback_mat[i, j] = i_penalty\n",
        "\n",
        "    # Traceback from bottom right\n",
        "    i = N - 1\n",
        "    j = M - 1\n",
        "    path = [(i, j)]\n",
        "    while i > 0 or j > 0:\n",
        "        tb_type = traceback_mat[i, j]\n",
        "        if tb_type == 0:\n",
        "            # Match\n",
        "            i = i - 1\n",
        "            j = j - 1\n",
        "        elif tb_type == 1:\n",
        "            # Insertion\n",
        "            i = i - 1\n",
        "        elif tb_type == 2:\n",
        "            # Deletion\n",
        "            j = j - 1\n",
        "        path.append((i, j))\n",
        "\n",
        "    # Strip infinity edges from cost_mat before returning\n",
        "    cost_mat = cost_mat[1:, 1:]\n",
        "    return (path[::-1], cost_mat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_path_costmat(x, y):    \n",
        "    N = x.shape[0]\n",
        "    M = y.shape[0]\n",
        "    print(\"Shape:\", N, M)\n",
        "    dist_mat = np.zeros((N, M))\n",
        "    for i in range(N):\n",
        "        for j in range(M):\n",
        "            dist_mat[i, j] = abs(x[i] - y[j])\n",
        "\n",
        "    # DTW\n",
        "    path, cost_mat = dp(dist_mat)\n",
        "    print(\"Alignment cost: {:.4f}\".format(cost_mat[N - 1, M - 1]))\n",
        "    print(\"Normalized alignment cost: {:.4f}\".format(cost_mat[N - 1, M - 1]/(N + M)))\n",
        "\n",
        "    return path, cost_mat, dist_mat\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### DTW Alternative version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_euclidean_distance_matrix(x, y) -> np.array:\n",
        "    \"\"\"Calculate distance matrix\n",
        "    This method calcualtes the pairwise Euclidean distance between two sequences.\n",
        "    The sequences can have different lengths.\n",
        "    \"\"\"\n",
        "    dist = np.zeros((len(y), len(x)))\n",
        "    for i in range(len(y)):\n",
        "        for j in range(len(x)):\n",
        "            dist[i,j] = (x[j]-y[i])**2\n",
        "    return dist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_accumulated_cost_matrix(x, y) -> np.array:\n",
        "    \"\"\"Compute accumulated cost matrix for warp path using Euclidean distance\n",
        "    \"\"\"\n",
        "    distances = compute_euclidean_distance_matrix(x, y)\n",
        "\n",
        "    # Initialization\n",
        "    cost = np.zeros((len(y), len(x)))\n",
        "    cost[0,0] = distances[0,0]\n",
        "    \n",
        "    for i in range(1, len(y)):\n",
        "        cost[i, 0] = distances[i, 0] + cost[i-1, 0]  \n",
        "        \n",
        "    for j in range(1, len(x)):\n",
        "        cost[0, j] = distances[0, j] + cost[0, j-1]  \n",
        "\n",
        "    # Accumulated warp path cost\n",
        "    for i in range(1, len(y)):\n",
        "        for j in range(1, len(x)):\n",
        "            cost[i, j] = min(\n",
        "                cost[i-1, j],    # insertion\n",
        "                cost[i, j-1],    # deletion\n",
        "                cost[i-1, j-1]   # match\n",
        "            ) + distances[i, j] \n",
        "            \n",
        "    return cost"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Plot DTW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_dtw(dist_mat, cost_mat, path):\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    plt.subplot(121)\n",
        "    plt.title(\"Distance matrix\")\n",
        "    plt.imshow(dist_mat, cmap=plt.cm.binary,\n",
        "            interpolation=\"nearest\", origin=\"lower\")\n",
        "    plt.subplot(122)\n",
        "    plt.title(\"Cost matrix\")\n",
        "    plt.imshow(cost_mat, cmap=plt.cm.binary,\n",
        "            interpolation=\"nearest\", origin=\"lower\")\n",
        "    x_path, y_path = zip(*path)\n",
        "    plt.plot(y_path, x_path)\n",
        "\n",
        "def plot_dtw_path(x, y, path):\n",
        "    plt.figure()\n",
        "    for x_i, y_j in path:\n",
        "        plt.plot([x_i, y_j], [x[x_i] + 1.5, y[y_j] - 1.5], c=\"C7\")\n",
        "    plt.plot(np.arange(x.shape[0]), x + 1.5, \"-o\", c=\"C3\")\n",
        "    plt.plot(np.arange(y.shape[0]), y - 1.5, \"-o\", c=\"C0\")\n",
        "    plt.axis(\"off\")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot DTW Alternative"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_dwt_alternative(cost_matrix, warp_path):\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12, 8))\n",
        "    ax = sbn.heatmap(cost_matrix, annot=True, square=True, linewidths=0.1, cmap=\"YlGnBu\", ax=ax)\n",
        "    ax.invert_yaxis()\n",
        "\n",
        "    # Get the warp path in x and y directions\n",
        "    path_x = [p[0] for p in warp_path]\n",
        "    path_y = [p[1] for p in warp_path]\n",
        "\n",
        "    # Align the path from the center of each cell\n",
        "    path_xx = [x+0.5 for x in path_x]\n",
        "    path_yy = [y+0.5 for y in path_y]\n",
        "\n",
        "    ax.plot(path_xx, path_yy, color='blue', linewidth=3, alpha=0.2)\n",
        "\n",
        "    fig.savefig(\"ex1_heatmap.png\", **savefig_options)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCChRLvek7w0"
      },
      "source": [
        "### Main Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_P3Dpd-gTPz"
      },
      "outputs": [],
      "source": [
        "# Compute ORDERBOOK Columns\n",
        "ORDERBOOK_COLUMNS = compute_orderbook_columns(int(LEVEL))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NQT_xfBaxcf"
      },
      "outputs": [],
      "source": [
        "def see_ticker_stat(ticker):\n",
        "  # Name: TICKER_Year-Month-Day_StartTime_EndTime_message_LEVEL.csv \t\n",
        "  NAME_MSG = ticker + \"_\" + DATE + \"_\" + START_TIME + \"_\" + END_TIME + \"_\" + MESSAGE[0] + \"_\" + LEVEL + \".cvs\"\n",
        "  NAME_ORD = ticker + \"_\" + DATE + \"_\" + START_TIME + \"_\" + END_TIME + \"_\" + MESSAGE[1] + \"_\" + LEVEL + \".cvs\"\n",
        "  path_msg = LOCAL_PATH + \"/\" + NAME_MSG\n",
        "  path_ord = LOCAL_PATH + \"/\" + NAME_ORD\n",
        "\n",
        "  file_path_msg =  Path(path_msg)\n",
        "  file_path_ord =  Path(path_ord)\n",
        "\n",
        "  # Download the dataset if it not exists\n",
        "  if file_path_msg.exists() and file_path_ord.exists():\n",
        "    print(\"Datasets of \", ticker, \" exist!\")\n",
        "  else:\n",
        "    URL = \"https://lobsterdata.com/info/sample/LOBSTER_SampleFile_\" + ticker + \"_\" + DATE + \"_\" + LEVEL + \".zip\"\n",
        "    r = requests.get(URL)\n",
        "    z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "    z.extractall(LOCAL_PATH)\n",
        "\n",
        "\n",
        "  # Message Dataframe\n",
        "  message_df = get_dataframe(ticker, MESSAGE[0], MESSAGE_COLUMNS)\n",
        "  \n",
        "  # Orderbook Dataframe\n",
        "  orderbook_df = get_dataframe(ticker, MESSAGE[1], ORDERBOOK_COLUMNS)\n",
        "\n",
        "  # Joined\n",
        "  joined_lob_df = compute_joined_lob(message_df, orderbook_df)\n",
        "\n",
        "  # Date Range\n",
        "  # df_range_date = select_date_range(joined_lob_df,  \"2012-06-21 09:30:00\", \"2012-06-21 09:35:00\")\n",
        "\n",
        "  # OHLC and Volume\n",
        "  # df_ohlc = plot_ohlc_volume(df_range_date)\n",
        "  df_ohlc = compute_ohlc_volume(joined_lob_df)\n",
        "\n",
        "  # Compute the R-value, we use the Rolling Mean\n",
        "  df_ohlc = compute_r(df_ohlc)\n",
        "\n",
        "  # Compute Bollinger Band\n",
        "  cl_buyers, cl_sellers, cl_upper_band, cl_lower_band, sma_cl = compute_bollinger_band(df_ohlc,\"close\")\n",
        "  vl_buyers, vl_sellers, vl_upper_band, vl_lower_band, sma_vl = compute_bollinger_band(df_ohlc,\"volume\")\n",
        "\n",
        "  # Plot Bollinger Band\n",
        "  plot_bollinger_band(cl_buyers, cl_sellers, cl_upper_band, cl_lower_band, sma_cl, df_ohlc, \"close\", ticker)\n",
        "  plot_bollinger_band(vl_buyers, vl_sellers, vl_upper_band, vl_lower_band, sma_vl, df_ohlc, \"volume\", ticker)\n",
        "  \n",
        "  # Compute MSI\n",
        "  # mfi = compute_msi(df_ohlc)\n",
        "  # df_ohlc[\"mfi\"] = mfi\n",
        "\n",
        "  # Plot MSI\n",
        "  # plot_mfi(df_ohlc)\n",
        "\n",
        "  # DTW\n",
        "  \"\"\"\n",
        "  x = df_ohlc[\"close\"]\n",
        "  y = df_ohlc[\"volume\"]\n",
        "  if NORMALIZE:\n",
        "      scaler = StandardScaler()\n",
        "      reshape = x.values.reshape(-1, 1)\n",
        "      x = scaler.fit_transform(reshape)\n",
        "      reshape = y.values.reshape(-1, 1)\n",
        "      y = scaler.fit_transform(reshape)\n",
        "  else:\n",
        "    # Compute Pearson Correlation Coefficient\n",
        "    # Note: we compute if only if our data are not normalized\n",
        "    pcc = np.corrcoef(x,y)\n",
        "    print(\"Pearson Correlation Coefficient: \", pcc[0,1])\n",
        "  path, cost_mat, dist_mat = compute_path_costmat(x, y)\n",
        "  \n",
        "  plot_dtw(dist_mat, cost_mat, path)\n",
        "  plot_dtw_path(x, y, path)\n",
        "  \"\"\"\n",
        "\n",
        "  # DTW alternative\n",
        "  x = df_ohlc[\"close\"]\n",
        "  y = df_ohlc[\"volume\"]\n",
        "  if NORMALIZE:\n",
        "    scaler = StandardScaler()\n",
        "    reshape = x.values.reshape(-1,1)\n",
        "    x = scaler.fit_transform(reshape)\n",
        "    reshape = y.values.reshape(-1,1)\n",
        "    y = scaler.fit_transform(reshape)\n",
        "  # compute the distance\n",
        "  dtw_distance, warp_path = fastdtw(x, y, dist=euclidean)\n",
        "  cost_matrix = compute_accumulated_cost_matrix(x, y)\n",
        "  # Print the values of the DTW distance and warp path\n",
        "  print(\"DTW distance: \", dtw_distance)\n",
        "  print(\"Warp path: \",  warp_path)\n",
        "  # Plot\n",
        "  plot_dwt_alternative(cost_matrix, warp_path)  \n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6075DqAOa0Aj"
      },
      "source": [
        "## Plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbA6La-4a7r0"
      },
      "source": [
        "### Amazon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bAkO1tCxa87H",
        "outputId": "00819c23-e091-4766-9a44-5524bcf4cc13"
      },
      "outputs": [],
      "source": [
        " # AMZN\n",
        "see_ticker_stat(TICKERS[0])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Considerations\n",
        "\n",
        "With Normalization, from the cost matrix graph, we can see that there are misalignments that lead the optimal path away from the diagonal. Furthermore, we can observe that the optimal path approaches the diagonal only at the opening and closing of the markets."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Apple "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#see_ticker_stat(TICKERS[1])\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Considerations\n",
        "\n",
        "With Normalization, from the cost matrix graph, we can see that there are misalignments that lead the optimal path away from the diagonal."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Google"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#see_ticker_stat(TICKERS[2])\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Considerations\n",
        "\n",
        "With Normalization, from the cost matrix graph, we can see that there are misalignments that lead the optimal path away from the diagonal. "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Intel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#see_ticker_stat(TICKERS[3])\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Considerations\n",
        "\n",
        "With Normalization, from the cost matrix graph, we can see that there are misalignments that lead the optimal path away from the diagonal."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Microsoft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#see_ticker_stat(TICKERS[4])\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Considerations\n",
        "\n",
        "With Normalization, from the cost matrix graph, we can see that there are misalignments that lead the optimal path away from the diagonal. "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Table for Pearson Correlation Coefficient"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The value will be a number between -1 and 1, where 1 is a perfect positive linear relationship, 0 is no linear relationship, and -1 is a perfect negative linear relationship. Different authors use slightly different interpretations of the coefficients, but they’re generally very similar to the ones below."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "| Pearson's r value\t| Strength of relationship                  |\n",
        "|-------------------|-------------------------------------------|\n",
        "| 0\t                | No linear relationship                    |\n",
        "| 0.1 to 0.3\t    | Weak linear relationship                  |\n",
        "| 0.3 to 0.5\t    | Moderate linear relationship              |\n",
        "| 0.5 to 0.7\t    | Strong linear relationship                |\n",
        "| 0.7 to 1\t        | Very strong linear relationship           |\n",
        "| -0.1 to -0.3\t    | Weak negative linear relationship         |\n",
        "| -0.3 to -0.5\t    | Moderate negative linear relationship     |\n",
        "| -0.5 to -0.7\t    | Strong negative linear relationship       |\n",
        "| -0.7 to -1\t    | Very strong negative linear relationship  |"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The Pearson Correlation Coefficient for all the stocks of our Dataframe is on the range `[0, -0.3]` this means that we have a weak negative linear relationship as we can see from the table.    "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "mdCedOLyaQdk",
        "_Hcsrh6alGLE",
        "6Q44NrX4kzvc"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
